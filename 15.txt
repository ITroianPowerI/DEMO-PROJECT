### 1.5 Кластеризация
______________________________

Подготовка данных
Отдельно возьму атрибуты, которые буду визуализировать
__________________________________

#Помещу их в переменную X
X = df_mer[["AGE", "GENDER", "EDUCATION_LEVEL"]]
___________________________________
Я выбрал эти атрибуты, так как в зависимости от региона и категории товара (продовца) стоимость покупок будет разной и я считаю, что этих атрибутов будет достаточно что бы модель не имела проблем с переобучением и недообучением
___________________________________
#### MinMaxScaler
Преобразование характеристик путем масштабирования каждой характеристики в заданном диапазоне. Этот оценщик масштабирует и переводит каждый признак в отдельности таким образом,чтобы он находился в заданном диапазоне на обучающем множестве,например,между нулем и единицей.
____________________________________
#обьявляю MinMaxScaler
scaler = MinMaxScaler()
#преобразую данные
X = scaler.fit_transform(X)
______________________________________
#### PCA
Метод главных компонент — один из основных способов уменьшить размерность данных, потеряв наименьшее количество информации.
_____________________________________
#Обьявляю метод главных компонент
pca = PCA(n_components=2)
#Применяю его на данных
X = pca.fit_transform(X)
_________________________________________
#### Функция визуализации
Отдельно вынесу функцию для визуализации
____________________________________________
#Функция для визуализации распределения 
def viz(prediction):
    #Размер фигуры
    plt.figure(figsize=(12, 12))
    plt.subplot(224)
    #Выводить изображение буду при помощи scatter
    plt.scatter(X[:, 0], X[:, 1], c=prediction)
    plt.title("Unevenly Sized Blobs")
    #Вывод изображения
    plt.show()
_________________________________________________
#### Выбор алгоритмов (KMeans, MiniBatchKMeans, GaussianMixtures)
Я решил взять алгоритмы KMeans, MiniBatchKMeans и GaussianMixtures, так как они идеально подходят для такого набора данных, они сочетают в себе скорость работы, а так же качество кластеризации
_____________________________________________
#### KMeans
______________________________________________
#Настройка параметров
kmeans = KMeans(n_clusters=4, random_state=0).fit(X)
#Предсказание
kmpreds = kmeans.predict(X)
#Заношу кластеризированные метки в набор данных
df_mer["KMCLUSTS"] = kmpreds

#Применяю функцию описаную выше
viz(df_mer["KMCLUSTS"])
_____________________________________________
#### MiniBatchKMeans
______________________________________________
#Настройка параметров
kbmeans = MiniBatchKMeans(n_clusters=4, random_state=0, batch_size=4096)
#Заношу кластеризированные метки в набор данных
df_mer["KBCLUSTS"] = kbmeans.fit_predict(X)

viz(df_mer["KBCLUSTS"])
__________________________________________________
#### GaussianMixture
__________________________________________
#Настройка параметров
gm = GaussianMixture(n_components=2, random_state=0).fit_predict(X)
#Заношу кластеризированные метки в набор данных
df_mer["GMCLUSTS"] = gm

viz(df_mer["GMCLUSTS"])
__________________________________________
#### Результаты метрик
__________________________________________
##### Kmeans 
__________________________________________
#Использую метрику calinski_harabasz_score
print(sklearn.metrics.calinski_harabasz_score(X, df_mer["KMCLUSTS"]))
#Использую метрику davies_bouldin_score
print(sklearn.metrics.davies_bouldin_score(X, df_mer["KMCLUSTS"]))
__________________________________________
##### MiniBatchKmeans
__________________________________________
#Использую метрику calinski_harabasz_score
print(sklearn.metrics.calinski_harabasz_score(X, df_mer["KBCLUSTS"]))
#Использую метрику davies_bouldin_score
print(sklearn.metrics.davies_bouldin_score(X, df_mer["KBCLUSTS"]))
___________________________________________
##### GussianMixture
___________________________________________
#Использую метрику calinski_harabasz_score
print(sklearn.metrics.calinski_harabasz_score(X, df_mer["GMCLUSTS"]))
#Использую метрику davies_bouldin_score
print(sklearn.metrics.davies_bouldin_score(X, df_mer["GMCLUSTS"]))
___________________________________________
#### Решение
По результатам метрик и визуализаций, лучшим алгоритмом является GussianMixture
___________________________________________
# Удаление ненужных атрибутов с кластерами
df_mer.drop(columns=['KMCLUSTS', 'KBCLUSTS'], axis=1, inplace=True)
___________________________________________
